{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import svm, neighbors, tree, ensemble, model_selection, metrics\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder containing the CSVs\n",
    "data_folder = \"data/traces/\"\n",
    "\n",
    "def read_date(dates: [str]):\n",
    "    \"\"\"Aggregate data of a single from parts\"\"\"\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for date in dates:\n",
    "        for i in range(50):\n",
    "            try:\n",
    "                frame = pd.read_csv(data_folder + date + \"-{}.csv\".format(i))\n",
    "                data = pd.concat([data, frame], axis=0)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_date_part(date_part: str):\n",
    "    \"\"\"Read data of a part of a capture date\"\"\"\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        frame = pd.read_csv(data_folder + date_part + \".csv\")\n",
    "        data = pd.concat([data, frame], axis=0)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    return data\n",
    "\n",
    "data = read_date([\"16-09\",\"16-10\"])\n",
    "\n",
    "data.set_index(\"timestamp\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def devices(df : pd.DataFrame, incl_camera : bool) -> pd.DataFrame:\n",
    "    if incl_camera :\n",
    "        return df.drop('incl', axis=1)\n",
    "    else :\n",
    "        df[df['incl']].drop('incl', axis=1)\n",
    "\n",
    "devices = devices(pd.read_csv(\"./data/list_of_devices.csv\"), True)\n",
    "\n",
    "devices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mode_mean_med(df: pd.DataFrame, devices: pd.DataFrame):\n",
    "    \"\"\"Calculate the mode, mean, and median of a window\"\"\"\n",
    "\n",
    "    # Keep only the device name and mac address\n",
    "    device_names = devices.loc[:, ['device_name', 'eth_src']]\n",
    "\n",
    "    # Keep only the mac address name and package size\n",
    "    df_size =  df[df['iot']].loc[:, ['eth_src', 'packet_size']]\n",
    "\n",
    "    # Merge the stats with the devices names\n",
    "    merge_df = device_names.merge(df_size, on='eth_src')\n",
    "\n",
    "    # Group the merged frame and calculate the stats\n",
    "    stats = merge_df.groupby(['device_name']).agg({'packet_size': ['mean', 'median', lambda x: x.mode().iat[0]]})\n",
    "\n",
    "    return stats\n",
    "\n",
    "statistics = mode_mean_med(data, devices)\n",
    "\n",
    "statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_window_id(timestamped_frame: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "    \"\"\"Slice the dataframe into 1-second intervals\"\"\"\n",
    "    first_packet_time = timestamped_frame.iloc[0]['timestamp']\n",
    "    last_packet_time = timestamped_frame.iloc[-1]['timestamp']\n",
    "    windowed_frame = timestamped_frame.set_index('timestamp', drop=False)\n",
    "\n",
    "    ns_in_sec = int(1e9)\n",
    "    number_of_windows = int((last_packet_time - first_packet_time) / ns_in_sec) + 1\n",
    "\n",
    "    try:\n",
    "        windowed_frame.insert(0, value=0, column=\"window_id\")\n",
    "    except Exception as e:\n",
    "        print(\"It seems like the column 'window_id' already exists. Just updating values...\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        windowed_frame.window_id.astype(np.int64)\n",
    "\n",
    "    for window_id in range(0, number_of_windows):\n",
    "        from_time = first_packet_time + window_id * ns_in_sec\n",
    "        to_time = first_packet_time + (window_id  + 1) * ns_in_sec\n",
    "        windowed_frame.loc[from_time:to_time, 'window_id'] = window_id\n",
    "\n",
    "    windowed_frame.set_index('window_id', inplace=True)\n",
    "    return windowed_frame\n",
    "\n",
    "\n",
    "def attach_window_id_fast(timestamped_frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    first_packet_time = timestamped_frame.iloc[0]['timestamp']\n",
    "    last_packet_time = timestamped_frame.iloc[-1]['timestamp']\n",
    "\n",
    "    ns_in_sec = int(1e9)\n",
    "    windows = range(first_packet_time - 1, last_packet_time + ns_in_sec, ns_in_sec)\n",
    "\n",
    "    windowed_frame = pd.cut(timestamped_frame['timestamp'], windows, labels=range(len(windows) - 1)).to_frame()\n",
    "    windowed_frame.columns = [\"window_id\"]\n",
    "    return pd.concat([timestamped_frame, windowed_frame], axis=1).set_index('window_id')\n",
    "\n",
    "windowed_frame = attach_window_id_fast(data)\n",
    "\n",
    "windowed_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_labeled(windowed_frame: pd.DataFrame, device_frame: pd.DataFrame):\n",
    "    \"\"\"Calculate the mean, std, and number of bytes of a window for each device\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    for device_index in device_frame.index:\n",
    "        device = device_frame.iloc[device_index]\n",
    "        device_packets = windowed_frame.loc[windowed_frame['eth_src'] == device['eth_src']]\n",
    "        device_features = generate_features(device_packets)\n",
    "\n",
    "        device_features.insert(len(device_features.columns), \"device_name\", device['device_name'])\n",
    "        device_features.insert(len(device_features.columns), \"iot\", device['iot'])\n",
    "\n",
    "        features = pd.concat([features, device_features])\n",
    "\n",
    "    features.columns = [\"mean\", \"std\", \"n_bytes\", \"device_name\", \"iot\"]\n",
    "    return features\n",
    "\n",
    "def generate_features(windowed_frame: pd.DataFrame):\n",
    "    window_groups = windowed_frame.groupby(\"window_id\", observed=True)\n",
    "\n",
    "    mean = window_groups['packet_size'].mean()\n",
    "    std = window_groups['packet_size'].std()\n",
    "    n_bytes = window_groups['packet_size'].sum()\n",
    "\n",
    "    # TODO Not sure if fillna is a good idea\n",
    "    return pd.concat([mean, std, n_bytes], axis=1).fillna(0)\n",
    "\n",
    "def get_devices_in_window(windowed_frame: pd.DataFrame):\n",
    "    devices_in_window = pd.DataFrame()\n",
    "\n",
    "    for window_id in windowed_frame.index.unique():\n",
    "        devices = windowed_frame.loc[window_id]['device_name']\n",
    "        # iot = windowed_frame.loc[window_id]['iot']\n",
    "\n",
    "        if not isinstance(devices, str):\n",
    "            devices = devices.unique()\n",
    "\n",
    "        devices_in_window = pd.concat([devices_in_window, pd.DataFrame({\"window_id\": window_id, \"devices\": devices})])\n",
    "\n",
    "    return devices_in_window\n",
    "\n",
    "labeled_features = generate_features_labeled(windowed_frame, devices)\n",
    "\n",
    "labeled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import StrEnum\n",
    "\n",
    "class Balancing(StrEnum):\n",
    "    NONE = \"none\"\n",
    "    STRATIFIED = \"stratified\"\n",
    "    OVER_UNDER = \"over_under\"\n",
    "    OVER_UNDER_RUS = \"over_under_rus\"\n",
    "\n",
    "def _balance_over_under(X, y, rus=False, random_state: int | None = None):\n",
    "    oversampling = SMOTE(random_state=random_state)\n",
    "\n",
    "    # Resource [32] is actually really old (2009), NearMiss is a better alternative than RUS\n",
    "    # but I left it as an option\n",
    "    if rus:\n",
    "        undersampling = RandomUnderSampler(random_state=random_state)\n",
    "    else:\n",
    "        undersampling = NearMiss()\n",
    "\n",
    "    # first oversample, then undersample\n",
    "    X, y = oversampling.fit_resample(X, y)\n",
    "    X, y = undersampling.fit_resample(X, y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def _get_models():\n",
    "    models = {\n",
    "        \"Knn\" : neighbors.KNeighborsClassifier(n_neighbors=5, weights=\"distance\"),\n",
    "        # \"SVM\" : svm.SVC(),\n",
    "        \"DT\"  : tree.DecisionTreeClassifier(),\n",
    "        \"RF\"  : ensemble.RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "    }\n",
    "    # I don't really see the advantage of using an ensemble balancing method in conjuction with the\n",
    "    # under- and oversample techniques. I can't find any indication in the paper the referenced [32]\n",
    "    # that it actually works. So, I'm just keeping this here.\n",
    "    models[\"Majority Voting\"] = ensemble.VotingClassifier(list(models.items()), voting='hard')\n",
    "\n",
    "    return models\n",
    "\n",
    "def train_and_test_classifiers(labeled_features, target_label, balancing=Balancing.NONE, n_splits=10, shuffle=False, random_state=None):\n",
    "    \"\"\"\n",
    "    Trains and tests a series of models on the given, labeled data\n",
    "    (Knn, RF, DT, SVM, Majority Voting)\n",
    "\n",
    "    When n_splits == 1, KFold is not used and the test set has a size of 25%\n",
    "    \"\"\"\n",
    "    assert not (balancing == \"stratified\" and n_splits < 1) # KFold cannot be disable if using the stratified balancing strategy\n",
    "\n",
    "    X = labeled_features.iloc[:, 1:3]\n",
    "    y = labeled_features.iloc[:][target_label]\n",
    "\n",
    "    # kf cross validation is still a good idea for testing the iot performance, not actually done in the paper tho\n",
    "    if n_splits > 1:\n",
    "        kf = model_selection.KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    # Balancing\n",
    "    if balancing == \"under_over\":\n",
    "        X, y = _balance_over_under(X, y, random_state=random_state)\n",
    "    if balancing == \"under_over_rus\":\n",
    "        X, y = _balance_over_under(X, y, rus=True, random_state=random_state)\n",
    "    if balancing == \"stratified\":\n",
    "        kf = model_selection.StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    models = _get_models()\n",
    "    scores = {\"model\" : [], \"accuracy\" : [], \"label\" : [], \"balancing\" : []}\n",
    "    trained = {}\n",
    "\n",
    "    if n_splits > 1:\n",
    "        folds = [ (X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test]) for (train, test) in kf.split(X, y) ]\n",
    "    else:\n",
    "        folds = [model_selection.train_test_split(X, y, test_size=.25, random_state=random_state)]\n",
    "\n",
    "    print(\"Fitting on target {} using '{}' balancing and {} folds\".format(target_label, balancing, \"no\" if n_splits == 1 else n_splits))\n",
    "    for (name, model) in models.items():\n",
    "        for (X_train, X_test, y_train, y_test) in folds:\n",
    "            trained[name] = model.fit(X_train, y_train)\n",
    "\n",
    "            scores[\"model\"].append(name)\n",
    "            scores[\"accuracy\"].append(metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "            scores[\"label\"].append(target_label)\n",
    "            scores[\"balancing\"].append(balancing)\n",
    "\n",
    "    return trained, pd.DataFrame(scores)\n",
    "\n",
    "# for the device classifier, we only consider iot devices\n",
    "device_features = labeled_features.loc[labeled_features['iot'] == True]\n",
    "\n",
    "# Balancing as done in the paper\n",
    "iot_classfiers, iot_scores = train_and_test_classifiers(labeled_features, 'iot', balancing=Balancing.OVER_UNDER_RUS, n_splits=1)\n",
    "device_classifier, device_scores = train_and_test_classifiers(device_features, 'device_name', balancing=Balancing.STRATIFIED)\n",
    "\n",
    "# Balancing strategies reversed\n",
    "iot_classfiers_diff, iot_scores_diff = train_and_test_classifiers(labeled_features, 'iot', balancing=Balancing.STRATIFIED)\n",
    "device_classifier_diff, device_scores_diff = train_and_test_classifiers(device_features, 'device_name', balancing=Balancing.OVER_UNDER_RUS, n_splits=1)\n",
    "\n",
    "# Balancing without RUS (with NearMiss)\n",
    "iot_classfiers_nm, iot_scores_nm = train_and_test_classifiers(labeled_features, 'iot', balancing=Balancing.OVER_UNDER, n_splits=1)\n",
    "\n",
    "# No balancing for either\n",
    "iot_classfiers_unb, iot_scores_unb = train_and_test_classifiers(labeled_features, 'iot', balancing=Balancing.NONE)\n",
    "device_classifier_unb, device_scores_unb = train_and_test_classifiers(device_features, 'device_name', balancing=Balancing.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_performance_plot(scores):\n",
    "    sns.catplot(scores, x=\"model\", y=\"accuracy\", kind=\"bar\")\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "def draw_multiple_perf(scores):\n",
    "    assert \"balancing\" in scores.columns\n",
    "\n",
    "    sns.catplot(scores, x=\"model\", y=\"accuracy\", col=\"balancing\", row=\"label\", kind=\"bar\")\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "all_scores = pd.concat([iot_scores, device_scores, iot_scores_unb, device_scores_unb, iot_scores_diff, device_scores_diff, iot_scores_nm])\n",
    "\n",
    "draw_multiple_perf(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def test_realistic(iot_classifier, device_classifier, unlabeled_features, devices_in_window):\n",
    "    assert len(unlabeled_features) == len(devices_in_window)\n",
    "\n",
    "    # accuracy = metrics.accuracy_score(devices_in_window, iot_classifier.predict(unlabeled_features))\n",
    "    accuracy = metrics.accuracy_score(devices_in_window, device_classifier.predict(unlabeled_features))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "unlabeled_features = generate_features(windowed_frame)\n",
    "devices_in_window = get_devices_in_window(windowed_frame)\n",
    "\n",
    "test_realistic(iot_classifier, device_classifier, unlabeled_features, devices_in_window)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
